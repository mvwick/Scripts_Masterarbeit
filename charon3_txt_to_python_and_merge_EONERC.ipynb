{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the txt files from Charon3 and merge them with the data from charon4\n",
    "The data is not processed, its just saved in an easier to acces format.\n",
    "This notebook is only for the EONERC data.\n",
    "\n",
    "Run `charon4_txt_to_python.ipynb` before this one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Version information of the imported packages\n",
      "pandas: 1.4.1\n",
      "pickle: 4.0\n",
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from my_func_mvw.functions import get_abspath, read_pickle, write_pickle, read_pickle\n",
    "from my_func_mvw.functions_import_my_database import merge_data_year,import_my_database_pickle, import_complete_database\n",
    "\n",
    "print(\"Some Version information of the imported packages\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"pickle: {pickle.format_version}\")\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Input###################\n",
    "path_to_EONERC_data=r\"..\\EONERC\\Data\"\n",
    "data_save_csv=True # True False; not implementet yet\n",
    "data_save_pickle=True #True False; \n",
    "\n",
    "path_to_charon3_EONERC=[\n",
    "    r\"..\\EONERC\\Data\\unprocessed\\charon3_export_as_txt\"\n",
    "]\n",
    "######################################\n",
    "controller=3195 # only 3195 is used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_temp_to_df(path):\n",
    "    \"\"\"\"\"\"\n",
    "    #df = pd.read_csv(path,skiprows=7,decimal=\".\",delimiter=\"\\t\",index_col=0,error_bad_lines=False,warn_bad_lines=False)\n",
    "    df=pd.read_csv(path, skiprows=3,decimal=\",\",delimiter=\"\\t\",index_col=1, dtype=float, encoding=\"unicode_escape\")\n",
    "    df = df.drop(df.columns[0],axis=1)\n",
    "    df=df.T\n",
    "    df.index.names = ['Date']\n",
    "    df.index = pd.to_datetime(df.index, infer_datetime_format=True).tz_localize(None)\n",
    "    df.rename(columns=lambda x: int(float(x)), inplace=True)\n",
    "    df.columns.names=[\"Length [m]\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"8\",\"9\",\"10\",\"11\"]\n",
    "data_2020_charon3={}\n",
    "for chan in channels:\n",
    "    data_2020_charon3[chan] = import_temp_to_df(path_to_charon3_EONERC[0] + f\"\\\\chan{chan}.TXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "path_to_my_database_EONERC = path_to_EONERC_data\n",
    "path_to_my_database = path_to_my_database_EONERC + \"\\\\unprocessed\"\n",
    "\n",
    "if data_save_pickle:\n",
    "    save_to_pickle = path_to_my_database + \"\\\\data_from_charon3\\\\all_charon3_data_pickle\"\n",
    "    write_pickle(save_to_pickle, data_2020_charon3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data from Charon3 and Charon4\n",
    "If I find new data I may need to adjust this if the datasets overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_charon4 = import_my_database_pickle(2021,path_to_my_database + \"\\\\data_from_charon4\\\\pickle\", controller=3195) # alte year dependent version\n",
    "\n",
    "data_charon4=read_pickle(path_to_my_database + \"\\\\..\\\\data_all_charon4\")\n",
    "for channel in channels:\n",
    "    data_charon4[channel].index=pd.to_datetime(data_charon4[channel].index, infer_datetime_format=True).tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all={}\n",
    "for channel in channels:\n",
    "    data_all[channel]=pd.concat([data_charon4[channel],data_2020_charon3[channel]])\n",
    "    data_all[channel]=data_all[channel].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "path_to_my_database = path_to_EONERC_data\n",
    "\n",
    "if data_save_pickle:\n",
    "    #save_to_pickle = path_to_my_database + \"\\\\all_data_pickle\"\n",
    "    #write_pickle(save_to_pickle, data_all)\n",
    "\n",
    "    save_to_pickle = path_to_my_database + \"\\\\all_data\"\n",
    "    write_pickle(save_to_pickle, data_all)\n",
    "\n",
    "    # not needed to save them again at the moment\n",
    "    # save_to_pickle = path_to_my_database + \"\\\\2021_pickle\"\n",
    "    # write_pickle(save_to_pickle, data_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29bb46dac4ac1939543a1997a987c8ba0e6eacd9d5e001c58572fbace647ecc5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Mathis': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
